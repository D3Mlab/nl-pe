{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374284a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from itertools import product\n",
    "import math\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e58d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent  # points to nl-pe/\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "sys.path.insert(0, str(SRC_PATH))  # make nl_pe importable\n",
    "os.chdir(PROJECT_ROOT)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a030366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_vars_to_config(\n",
    "        data='',\n",
    "        embedder = '',\n",
    "        gpu_batch_size=None,\n",
    "        #gp\n",
    "        noise = None,\n",
    "        sigma_sig = None,\n",
    "        #Active Learning\n",
    "        acquisition_f = None,\n",
    "        #gr-eps\n",
    "        epsilon = None,\n",
    "        #ucb\n",
    "        ucb_beta_const = None,\n",
    "        ):\n",
    "\n",
    "    base_data_dir = os.path.join('data', 'ir', data)\n",
    "    embedder_dir = os.path.join(base_data_dir, embedder)\n",
    "\n",
    "    #set query label for dataset:\n",
    "    if data == 'beir\\\\nfcorpus' or data == 'beir\\trec-covid':\n",
    "        query_rel_label = 2\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown query label value for: {data}\")\n",
    "\n",
    "    var_config_mapping = {\n",
    "        'data': {\n",
    "            data: {\n",
    "                'data': {\n",
    "                    'd_text_csv': os.path.join(base_data_dir, 'docs.csv'),\n",
    "                    'q_text_csv': os.path.join(base_data_dir, 'test_queries.csv'),\n",
    "                    'index_path': os.path.join(embedder_dir, 'faiss', 'index'),\n",
    "                    'doc_ids_path': os.path.join(embedder_dir, 'faiss', 'index_doc_ids.pkl'),\n",
    "                    'qrels_path': os.path.join(base_data_dir, 'qrels', 'test.txt'),\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'query_rel_label': {\n",
    "            query_rel_label: {\n",
    "                'gp': {'query_rel_label': query_rel_label},\n",
    "                }\n",
    "        },\n",
    "        'gpu_batch_size': {\n",
    "            gpu_batch_size: {\n",
    "                'embedding': {'inference_batch_size': gpu_batch_size},\n",
    "                'data': {'embedding_batch_size': gpu_batch_size},\n",
    "                }\n",
    "        },\n",
    "        'device': {\n",
    "            'gpu': {\n",
    "                'inference_device': 'gpu',\n",
    "                'tensor_ops_device': 'gpu',\n",
    "                },\n",
    "            'cpu': {\n",
    "                'inference_device': 'cpu',\n",
    "                'tensor_ops_device': 'cpu',}\n",
    "        },\n",
    "        #GP\n",
    "        'noise': {\n",
    "            noise: {\n",
    "                'gp': {'observation_noise': noise},\n",
    "                }\n",
    "        },\n",
    "        'sigma_sig': {\n",
    "            sigma_sig: {\n",
    "                'gp': {'signal_noise': sigma_sig},\n",
    "                }\n",
    "        },\n",
    "        #Active Learning\n",
    "        'acquisition_f': {\n",
    "            acquisition_f: {\n",
    "                'active_learning': {'acquisition_f': acquisition_f},\n",
    "                }\n",
    "        },\n",
    "        #UCB\n",
    "        'ucb_beta_const': {\n",
    "            ucb_beta_const: {\n",
    "                'active_learning': {'ucb_beta_const': ucb_beta_const},\n",
    "                }\n",
    "        },\n",
    "        #GR-EPS\n",
    "        'epsilon': {\n",
    "            epsilon: {\n",
    "                'active_learning': {'epsilon': epsilon},\n",
    "                }\n",
    "        },\n",
    "    }\n",
    "    return var_config_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99e318a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_update(original, update):\n",
    "    for key, value in update.items():\n",
    "        if isinstance(value, dict):\n",
    "            original[key] = deep_update(original.get(key, {}), value)\n",
    "        else:\n",
    "            original[key] = value\n",
    "    return original\n",
    "\n",
    "\n",
    "def save_config(config, base_dir, experiment_name):\n",
    "    full_path = os.path.join(base_dir, experiment_name)\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    with open(os.path.join(full_path, \"config.yaml\"), 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    #EMNLP EVAL CONFIG SAVING\n",
    "    # measures = []\n",
    "    # for i in range(1, 176):\n",
    "    #     measures.append(f\"ndcg_cut_{i}\")\n",
    "    # for i in range(1, 176):\n",
    "    #     measures.append(f\"map_cut_{i}\")\n",
    "    # for i in range(1, 176):\n",
    "    #     measures.append(f\"P_{i}\")\n",
    "    # for i in range(1, 176):\n",
    "    #     measures.append(f\"recall_{i}\")\n",
    "\n",
    "    # eval_params = {\n",
    "    #     'measures': measures,\n",
    "    #     'qrels_path' : os.path.join(os.path.dirname(config['data']['run_path']),'qrels.txt'),\n",
    "    #     'logging': {'level': 'DEBUG'},\n",
    "    # }\n",
    "\n",
    "    # with open(os.path.join(full_path, \"eval_config.yaml\"), 'w') as f:\n",
    "    #     yaml.dump(eval_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6c20c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR = 'trials/test_param_writer'\n",
    "if not os.path.exists(EXP_DIR):\n",
    "    os.makedirs(EXP_DIR)\n",
    "\n",
    "BASE_CONFIG_PATH = 'configs/base_config_dec23.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33038a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the parmeters\n",
    "#options/explanations of params:\n",
    "'''\n",
    "param_grid = {\n",
    "}\n",
    "'''\n",
    "\n",
    "# Define the parameters\n",
    "param_grid = {\n",
    "    'data': ['beir\\\\nfcorpus'],\n",
    "    'embedder': ['miniLM'],\n",
    "    ###device params\n",
    "    'gpu_batch_size': [1024],\n",
    "    'device': ['gpu'],\n",
    "    ###variances\n",
    "    'noise': [0.001],\n",
    "    'sigma_sig': [0.01],\n",
    "    ###acquisition_f\n",
    "    'acquisition_f': ['ucb_const_beta'],\n",
    "    ###gr-eps\n",
    "    'epsilon': [0.3],\n",
    "    ###ucb\n",
    "    'ucb_beta_const': [1,2],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c60b822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mapping found for parameter 'embedder' with value 'miniLM'\n",
      "No mapping found for parameter 'embedder' with value 'miniLM'\n"
     ]
    }
   ],
   "source": [
    "# Load the base config file\n",
    "with open(BASE_CONFIG_PATH, 'r') as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "#for file naming, don't use these param keys:\n",
    "PARAM_NAMES_TO_OMMIT = {'dataset', 'embedder'} #\n",
    "\n",
    "# Generate and save config files for each combination\n",
    "for param_values in product(*param_grid.values()):\n",
    "    param_values_dict = dict(zip(param_grid.keys(), param_values))\n",
    "    experiment_name = os.path.join(*[\n",
    "        str(value)\n",
    "        for param, value in param_values_dict.items()\n",
    "        if param not in PARAM_NAMES_TO_OMMIT\n",
    "    ])\n",
    "    updated_config = yaml.safe_load(yaml.dump(base_config))  # deep copy\n",
    "\n",
    "    # Apply updates to the config based on the current parameter values\n",
    "    var_config_mapping = map_vars_to_config(\n",
    "        #dimensionality can be set this way... for gemini\n",
    "        data=param_values_dict.get('data'),\n",
    "        embedder=param_values_dict.get('embedder'),\n",
    "        gpu_batch_size=param_values_dict.get('gpu_batch_size'),\n",
    "        noise=param_values_dict.get('noise'),\n",
    "        sigma_sig=param_values_dict.get('sigma_sig'),\n",
    "        acquisition_f=param_values_dict.get('acquisition_f'),\n",
    "        ucb_beta_const=param_values_dict.get('ucb_beta_const'),\n",
    "        epsilon=param_values_dict.get('epsilon'),\n",
    "    )\n",
    "    for param, value in param_values_dict.items():\n",
    "        if param in var_config_mapping and value in var_config_mapping[param]:\n",
    "            deep_update(updated_config, var_config_mapping[param][value])\n",
    "        else:\n",
    "            print(f\"No mapping found for parameter '{param}' with value '{value}'\")\n",
    "\n",
    "    save_config(updated_config, EXP_DIR, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d80d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
