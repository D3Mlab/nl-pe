{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35fb6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c638bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from botorch.test_functions import Hartmann\n",
    "\n",
    "\n",
    "neg_hartmann6 = Hartmann(negate=True).to(device=device)\n",
    "\n",
    "\n",
    "def outcome_constraint(X):\n",
    "    \"\"\"L1 constraint; feasible if less than or equal to zero.\"\"\"\n",
    "    return X.sum(dim=-1) - 3\n",
    "\n",
    "\n",
    "def weighted_obj(X):\n",
    "    \"\"\"Feasibility weighted objective; zero if not feasible.\"\"\"\n",
    "    return neg_hartmann6(X) * (outcome_constraint(X) <= 0).type_as(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c137e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "\n",
    "NOISE_SE = 0.25\n",
    "train_yvar = torch.tensor(NOISE_SE**2, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "def generate_initial_data(n=10):\n",
    "    # generate training data\n",
    "    train_x = torch.rand(10, 6, device=device, dtype=dtype)\n",
    "    exact_obj = neg_hartmann6(train_x).unsqueeze(-1)  # add output dimension\n",
    "    exact_con = outcome_constraint(train_x).unsqueeze(-1)  # add output dimension\n",
    "    train_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    train_con = exact_con + NOISE_SE * torch.randn_like(exact_con)\n",
    "    best_observed_value = weighted_obj(train_x).max().item()\n",
    "    return train_x, train_obj, train_con, best_observed_value\n",
    "\n",
    "\n",
    "def initialize_model(train_x, train_obj, train_con, state_dict=None):\n",
    "    # define models for objective and constraint\n",
    "    model_obj = SingleTaskGP(\n",
    "        train_x,\n",
    "        train_obj,\n",
    "        train_yvar.expand_as(train_obj),\n",
    "        input_transform=Normalize(d=train_x.shape[-1]),\n",
    "    ).to(train_x)\n",
    "    model_con = SingleTaskGP(\n",
    "        train_x,\n",
    "        train_con,\n",
    "        train_yvar.expand_as(train_con),\n",
    "        input_transform=Normalize(d=train_x.shape[-1]),\n",
    "    ).to(train_x)\n",
    "    # combine into a multi-output GP model\n",
    "    model = ModelListGP(model_obj, model_con)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    # load state dict if it is passed\n",
    "    if state_dict is not None:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb2209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition.objective import GenericMCObjective\n",
    "\n",
    "def obj_callable(Z: torch.Tensor, X: Optional[torch.Tensor] = None):\n",
    "    return Z[..., 0]\n",
    "\n",
    "\n",
    "def constraint_callable(Z):\n",
    "    return Z[..., 1]\n",
    "\n",
    "\n",
    "objective = GenericMCObjective(objective=obj_callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ed541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "bounds = torch.tensor([[0.0] * 6, [1.0] * 6], device=device, dtype=dtype)\n",
    "\n",
    "BATCH_SIZE = 3 if not SMOKE_TEST else 2\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 32\n",
    "\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    exact_obj = neg_hartmann6(new_x).unsqueeze(-1)  # add output dimension\n",
    "    exact_con = outcome_constraint(new_x).unsqueeze(-1)  # add output dimension\n",
    "    new_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    new_con = exact_con + NOISE_SE * torch.randn_like(exact_con)\n",
    "    return new_x, new_obj, new_con\n",
    "\n",
    "\n",
    "def update_random_observations(best_random):\n",
    "    \"\"\"Simulates a random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point, observing its value, and updating the list.\n",
    "    \"\"\"\n",
    "    rand_x = torch.rand(BATCH_SIZE, 6, device=device)\n",
    "    next_random_best = weighted_obj(rand_x).max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "    return best_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031ed039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4189], device='cuda:0', dtype=torch.float64), mean = tensor([0.3520], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4893], device='cuda:0', dtype=torch.float64), mean = tensor([-0.1966], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.5180], device='cuda:0', dtype=torch.float64), mean = tensor([0.5303], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4630], device='cuda:0', dtype=torch.float64), mean = tensor([-0.2685], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4926], device='cuda:0', dtype=torch.float64), mean = tensor([0.4937], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4960], device='cuda:0', dtype=torch.float64), mean = tensor([-0.2775], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.5147], device='cuda:0', dtype=torch.float64), mean = tensor([0.5840], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4634], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3563], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.5434], device='cuda:0', dtype=torch.float64), mean = tensor([0.5899], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4688], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3371], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.5297], device='cuda:0', dtype=torch.float64), mean = tensor([0.5986], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4630], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3529], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6389], device='cuda:0', dtype=torch.float64), mean = tensor([0.7396], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4874], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4295], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6580], device='cuda:0', dtype=torch.float64), mean = tensor([0.7349], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4582], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3780], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.7365], device='cuda:0', dtype=torch.float64), mean = tensor([0.7977], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6016], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4134], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.8434], device='cuda:0', dtype=torch.float64), mean = tensor([0.8662], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4531], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3716], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.7555], device='cuda:0', dtype=torch.float64), mean = tensor([0.8006], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6047], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3649], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.8600], device='cuda:0', dtype=torch.float64), mean = tensor([0.8766], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4366], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3631], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.8459], device='cuda:0', dtype=torch.float64), mean = tensor([0.8878], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.5944], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4110], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9026], device='cuda:0', dtype=torch.float64), mean = tensor([0.8934], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4615], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3432], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9382], device='cuda:0', dtype=torch.float64), mean = tensor([0.9424], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6706], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3666], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9382], device='cuda:0', dtype=torch.float64), mean = tensor([0.9005], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4511], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3444], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9567], device='cuda:0', dtype=torch.float64), mean = tensor([0.9993], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6573], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4128], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9767], device='cuda:0', dtype=torch.float64), mean = tensor([1.0103], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4470], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3714], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.9974], device='cuda:0', dtype=torch.float64), mean = tensor([1.0466], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6724], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4203], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([1.0176], device='cuda:0', dtype=torch.float64), mean = tensor([1.1139], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4637], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4124], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([1.0085], device='cuda:0', dtype=torch.float64), mean = tensor([1.0545], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6559], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4445], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([1.0447], device='cuda:0', dtype=torch.float64), mean = tensor([1.1377], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.4703], device='cuda:0', dtype=torch.float64), mean = tensor([-0.3919], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([1.0088], device='cuda:0', dtype=torch.float64), mean = tensor([1.0660], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n",
      "c:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:260: InputDataWarning: Data is not standardized (std = tensor([0.6747], device='cuda:0', dtype=torch.float64), mean = tensor([-0.4310], device='cuda:0', dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 78\u001b[0m\n\u001b[0;32m     69\u001b[0m qLogNEI \u001b[38;5;241m=\u001b[39m qLogNoisyExpectedImprovement(\n\u001b[0;32m     70\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_nei,\n\u001b[0;32m     71\u001b[0m     X_baseline\u001b[38;5;241m=\u001b[39mtrain_x_nei,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m     constraints\u001b[38;5;241m=\u001b[39m[constraint_callable],\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# optimize and get new observation\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m new_x_ei, new_obj_ei, new_con_ei \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf_and_get_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqLogEI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m new_x_nei, new_obj_nei, new_con_nei \u001b[38;5;241m=\u001b[39m optimize_acqf_and_get_observation(qLogNEI)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# update training points\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36moptimize_acqf_and_get_observation\u001b[1;34m(acq_func)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Optimizes the acquisition function, and returns a new candidate and a noisy observation.\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# optimize\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m candidates, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_RESTARTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRAW_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# used for intialization heuristic\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# observe new values\u001b[39;00m\n\u001b[0;32m     23\u001b[0m new_x \u001b[38;5;241m=\u001b[39m candidates\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:562\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[0;32m    540\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[0;32m    541\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[0;32m    542\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[0;32m    561\u001b[0m )\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:583\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:347\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    344\u001b[0m         batch_acq_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch_acq_values_list)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[1;32m--> 347\u001b[0m batch_candidates, batch_acq_values, ws \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_batch_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m optimization_warning_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    350\u001b[0m     (\u001b[38;5;28missubclass\u001b[39m(w\u001b[38;5;241m.\u001b[39mcategory, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws)\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised \u001b[38;5;129;01mand\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mretry_on_optimization_warning:\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\optim\\optimize.py:331\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[0;32m    327\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[0;32m    328\u001b[0m     (\n\u001b[0;32m    329\u001b[0m         batch_candidates_curr,\n\u001b[0;32m    330\u001b[0m         batch_acq_values_curr,\n\u001b[1;32m--> 331\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_ics_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m opt_warnings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ws\n\u001b[0;32m    335\u001b[0m batch_candidates_list\u001b[38;5;241m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\generation\\gen.py:252\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[1;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf\u001b[39m(x):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39macquisition_function(x)\n\u001b[1;32m--> 252\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_np_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSLSQP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwith_grad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m _process_scipy_result(res\u001b[38;5;241m=\u001b[39mres, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    270\u001b[0m candidates \u001b[38;5;241m=\u001b[39m fix_features(\n\u001b[0;32m    271\u001b[0m     X\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(res\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mto(initial_conditions)\u001b[38;5;241m.\u001b[39mreshape(shapeX),\n\u001b[0;32m    272\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[0;32m    273\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\optim\\utils\\timeout.py:82\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod .* cannot handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     97\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:784\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    781\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    782\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 784\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    787\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    788\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:469\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[0m\n\u001b[0;32m    461\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[0;32m    462\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:403\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:353\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 353\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:590\u001b[0m, in \u001b[0;36m_ScalarFunctionWrapper.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\botorch\\generation\\gen.py:211\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[1;34m(x, f)\u001b[0m\n\u001b[0;32m    209\u001b[0m loss \u001b[38;5;241m=\u001b[39m f(X_fix)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m gradf \u001b[38;5;241m=\u001b[39m _arrayify(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    213\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m element \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient array `gradf` are NaN. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis often indicates numerical issues.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:502\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    498\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    499\u001b[0m         grad_outputs_\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    513\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[0;32m    515\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\anton\\source\\repos\\nl-pe\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition import (\n",
    "    qLogExpectedImprovement,\n",
    "    qLogNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "N_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "N_BATCH = 20 if not SMOKE_TEST else 2\n",
    "MC_SAMPLES = 256 if not SMOKE_TEST else 32\n",
    "\n",
    "verbose = False\n",
    "\n",
    "best_observed_all_ei, best_observed_all_nei, best_random_all = [], [], []\n",
    "\n",
    "# average over multiple trials\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    best_observed_ei, best_observed_nei, best_random = [], [], []\n",
    "\n",
    "    # call helper functions to generate initial training data and initialize model\n",
    "    (\n",
    "        train_x_ei,\n",
    "        train_obj_ei,\n",
    "        train_con_ei,\n",
    "        best_observed_value_ei,\n",
    "    ) = generate_initial_data(n=10)\n",
    "    mll_ei, model_ei = initialize_model(train_x_ei, train_obj_ei, train_con_ei)\n",
    "\n",
    "    train_x_nei, train_obj_nei, train_con_nei = train_x_ei, train_obj_ei, train_con_ei\n",
    "    best_observed_value_nei = best_observed_value_ei\n",
    "    mll_nei, model_nei = initialize_model(train_x_nei, train_obj_nei, train_con_nei)\n",
    "\n",
    "    best_observed_ei.append(best_observed_value_ei)\n",
    "    best_observed_nei.append(best_observed_value_nei)\n",
    "    best_random.append(best_observed_value_ei)\n",
    "\n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_BATCH + 1):\n",
    "\n",
    "        t0 = time.monotonic()\n",
    "\n",
    "        # fit the models\n",
    "        fit_gpytorch_mll(mll_ei)\n",
    "        fit_gpytorch_mll(mll_nei)\n",
    "\n",
    "        # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "        qmc_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "\n",
    "        # for best_f, we use the best observed noisy values as an approximation\n",
    "        qLogEI = qLogExpectedImprovement(\n",
    "            model=model_ei,\n",
    "            best_f=(train_obj_ei * (train_con_ei <= 0).to(train_obj_ei)).max(),\n",
    "            sampler=qmc_sampler,\n",
    "            objective=objective,\n",
    "            constraints=[constraint_callable],\n",
    "        )\n",
    "\n",
    "        qLogNEI = qLogNoisyExpectedImprovement(\n",
    "            model=model_nei,\n",
    "            X_baseline=train_x_nei,\n",
    "            sampler=qmc_sampler,\n",
    "            objective=objective,\n",
    "            constraints=[constraint_callable],\n",
    "        )\n",
    "\n",
    "        # optimize and get new observation\n",
    "        new_x_ei, new_obj_ei, new_con_ei = optimize_acqf_and_get_observation(qLogEI)\n",
    "        new_x_nei, new_obj_nei, new_con_nei = optimize_acqf_and_get_observation(qLogNEI)\n",
    "\n",
    "        # update training points\n",
    "        train_x_ei = torch.cat([train_x_ei, new_x_ei])\n",
    "        train_obj_ei = torch.cat([train_obj_ei, new_obj_ei])\n",
    "        train_con_ei = torch.cat([train_con_ei, new_con_ei])\n",
    "\n",
    "        train_x_nei = torch.cat([train_x_nei, new_x_nei])\n",
    "        train_obj_nei = torch.cat([train_obj_nei, new_obj_nei])\n",
    "        train_con_nei = torch.cat([train_con_nei, new_con_nei])\n",
    "\n",
    "        # update progress\n",
    "        best_random = update_random_observations(best_random)\n",
    "        best_value_ei = weighted_obj(train_x_ei).max().item()\n",
    "        best_value_nei = weighted_obj(train_x_nei).max().item()\n",
    "        best_observed_ei.append(best_value_ei)\n",
    "        best_observed_nei.append(best_value_nei)\n",
    "\n",
    "        # reinitialize the models so they are ready for fitting on next iteration\n",
    "        # use the current state dict to speed up fitting\n",
    "        mll_ei, model_ei = initialize_model(\n",
    "            train_x_ei,\n",
    "            train_obj_ei,\n",
    "            train_con_ei,\n",
    "            model_ei.state_dict(),\n",
    "        )\n",
    "        mll_nei, model_nei = initialize_model(\n",
    "            train_x_nei,\n",
    "            train_obj_nei,\n",
    "            train_con_nei,\n",
    "            model_nei.state_dict(),\n",
    "        )\n",
    "\n",
    "        t1 = time.monotonic()\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: best_value (random, qEI, qNEI) = \"\n",
    "                f\"({max(best_random):>4.2f}, {best_value_ei:>4.2f}, {best_value_nei:>4.2f}), \"\n",
    "                f\"time = {t1-t0:>4.2f}.\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "    best_observed_all_ei.append(best_observed_ei)\n",
    "    best_observed_all_nei.append(best_observed_nei)\n",
    "    best_random_all.append(best_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
